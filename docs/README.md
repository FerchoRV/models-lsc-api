# API de Reconocimiento de Lenguaje de Se√±as Colombiano (LSC)

## Descripci√≥n del Proyecto

Este proyecto implementa una API REST para el reconocimiento autom√°tico de se√±as del Lenguaje de Se√±as Colombiano (LSC) utilizando modelos de Machine Learning basados en TensorFlow/Keras. La API puede procesar tanto secuencias de keypoints extra√≠dos de videos como videos completos para identificar se√±as del alfabeto y palabras comunes.

## Caracter√≠sticas Principales

- **Reconocimiento de Alfabeto LSC**: 27 letras (A-Z, √ë)
- **Reconocimiento de Palabras LSC**: 28 palabras comunes
- **Procesamiento de Videos**: Extracci√≥n autom√°tica de keypoints usando MediaPipe
- **M√∫ltiples Modos de Extracci√≥n**: 
  - `hands`: Solo puntos de las manos (126 caracter√≠sticas)
  - `pose_hands`: Puntos del cuerpo completo + manos (258 caracter√≠sticas)
- **Muestreo Distribuido**: Adaptaci√≥n inteligente de secuencias de video de diferentes longitudes
- **API REST**: Endpoints para predicci√≥n directa y procesamiento de videos

## Arquitectura del Sistema

### Componentes Principales

1. **API Flask**: Servidor web para manejo de requests HTTP
2. **Modelos TensorFlow**: 
   - `actionAbecedario.h5`: Modelo para reconocimiento del alfabeto
   - `actionPalabrasV2.h5`: Modelo para reconocimiento de palabras
3. **MediaPipe**: Extracci√≥n de keypoints de poses y manos
4. **OpenCV**: Procesamiento de video
5. **Docker**: Containerizaci√≥n para despliegue

### Estructura de Datos

- **Secuencia de Entrada**: Array de keypoints por frame
- **Longitud de Secuencia**: 30 frames (configurable en `constants.py`)
- **Caracter√≠sticas por Frame**:
  - Modo `hands`: 126 caracter√≠sticas (21 puntos √ó 3 coordenadas √ó 2 manos)
  - Modo `pose_hands`: 258 caracter√≠sticas (33 puntos pose √ó 4 coordenadas + 42 puntos manos √ó 3 coordenadas)

## Instalaci√≥n y Configuraci√≥n

### Prerrequisitos

- Python 3.10.11
- Docker (para despliegue)
- Google Cloud SDK (para despliegue en GCP)
- Git

### Instalaci√≥n Local

1. **Clonar el repositorio**:
```bash
git clone <repository-url>
cd models-lsc-api
```

2. **Crear entorno virtual**:
```bash
python -m venv _env
# Windows
_env\Scripts\activate
# Linux/Mac
source _env/bin/activate
```

3. **Instalar dependencias**:
```bash
pip install -r requirements.txt
```

4. **Verificar modelos**:
Aseg√∫rate de que los archivos de modelo est√©n en la carpeta `models/`:
- `models/actionAbecedario.h5`
- `models/actionPalabrasV2.h5`

5. **Ejecutar la aplicaci√≥n**:
```bash
python main.py
```

La API estar√° disponible en `http://localhost:5000`

### Configuraci√≥n de Variables de Entorno

```bash
# Puerto de la aplicaci√≥n (por defecto: 5000)
PORT=5000

# Configuraci√≥n de CORS (ya configurado en el c√≥digo)
# origins = ["http://localhost:3000", "https://www.colsign.com.co", "https://colsigns-app.vercel.app"]
```

## Uso de la API

### Endpoints Disponibles

#### 1. Health Check
```http
GET /
```
**Respuesta**: Mensaje de confirmaci√≥n de funcionamiento

#### 2. Reconocimiento de Alfabeto (Keypoints)
```http
POST /predict_recognition_alphabet
Content-Type: application/json

{
  "keypoints": [[x1, y1, z1, ...], [x2, y2, z2, ...], ...]
}
```

#### 3. Reconocimiento de Palabras V2 (Keypoints)
```http
POST /predict_recognition_words_v2
Content-Type: application/json

{
  "keypoints": [[x1, y1, z1, ...], [x2, y2, z2, ...], ...]
}
```

#### 4. Reconocimiento de Alfabeto (Video)
```http
POST /predict_recognition_video_alphabet
Content-Type: application/json

{
  "url_video": "https://ejemplo.com/video.mp4",
  "type_extract": "hands"  // o "pose_hands"
}
```

#### 5. Reconocimiento de Palabras V2 (Video)
```http
POST /predict_recognition_video_words_v2
Content-Type: application/json

{
  "url_video": "https://ejemplo.com/video.mp4",
  "type_extract": "pose_hands"  // o "hands"
}
```

### Formato de Respuesta

```json
{
  "prediction": "A",
  "probabilities": [0.1, 0.8, 0.05, ...]
}
```

### C√≥digos de Error

- `400`: Error en el formato de la solicitud
- `500`: Error interno del servidor

## Despliegue en Google Cloud Platform (GCP)

### Prerrequisitos de GCP

1. **Proyecto GCP configurado**
2. **Google Cloud SDK instalado**
3. **Docker instalado**
4. **Servicios habilitados**:
   - Cloud Run
   - Artifact Registry

### Configuraci√≥n del Proyecto

Edita el archivo `deploy-model-api.ps1` con tus configuraciones:

```powershell
$PROJECT_ID = "tu-proyecto-id"
$REGION = "us-central1"
$REPO_NAME = "model-api-repo"
$IMAGE_NAME = "model-lsc-api"
$SERVICE_NAME = "model-lsc-api"
```

### Despliegue Autom√°tico

1. **Autenticaci√≥n**:
```bash
gcloud auth login
gcloud config set project tu-proyecto-id
```

2. **Ejecutar script de despliegue**:
```bash
# Windows PowerShell
.\deploy-model-api.ps1

# Linux/Mac (convertir a bash)
chmod +x deploy-model-api.sh
./deploy-model-api.sh
```

### Despliegue Manual

1. **Construir imagen Docker**:
```bash
docker build -t model-lsc-api .
```

2. **Etiquetar imagen**:
```bash
docker tag model-lsc-api:latest us-central1-docker.pkg.dev/tu-proyecto-id/model-api-repo/model-lsc-api:latest
```

3. **Subir a Artifact Registry**:
```bash
docker push us-central1-docker.pkg.dev/tu-proyecto-id/model-api-repo/model-lsc-api:latest
```

4. **Desplegar en Cloud Run**:
```bash
gcloud run deploy model-lsc-api \
  --image=us-central1-docker.pkg.dev/tu-proyecto-id/model-api-repo/model-lsc-api:latest \
  --platform=managed \
  --region=us-central1 \
  --allow-unauthenticated \
  --port=5000
```

### Configuraci√≥n de Cloud Run

- **Memoria**: 2GB (recomendado para modelos ML)
- **CPU**: 1 vCPU
- **Concurrencia**: 80 requests simult√°neos
- **Timeout**: 300 segundos (para procesamiento de video)

## Estructura del Proyecto

```
models-lsc-api/
‚îú‚îÄ‚îÄ main.py                 # Aplicaci√≥n Flask principal
‚îú‚îÄ‚îÄ utils.py               # Utilidades para procesamiento de video
‚îú‚îÄ‚îÄ constants.py           # Constantes y configuraciones
‚îú‚îÄ‚îÄ tools.py              # Herramientas adicionales
‚îú‚îÄ‚îÄ requirements.txt      # Dependencias principales
‚îú‚îÄ‚îÄ requirements_full.txt # Dependencias completas
‚îú‚îÄ‚îÄ Dockerfile           # Configuraci√≥n de Docker
‚îú‚îÄ‚îÄ deploy-model-api.ps1 # Script de despliegue (Windows)
‚îú‚îÄ‚îÄ deploy-model-api.sh  # Script de despliegue (Linux/Mac)
‚îú‚îÄ‚îÄ cloudbuild.yaml      # Configuraci√≥n CI/CD
‚îú‚îÄ‚îÄ docker-compose.yml   # Configuraci√≥n para desarrollo
‚îú‚îÄ‚îÄ env.example         # Variables de entorno de ejemplo
‚îú‚îÄ‚îÄ docs/               # üìö Documentaci√≥n completa
‚îÇ   ‚îú‚îÄ‚îÄ INDEX.md        # √çndice de documentaci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ README.md       # Documentaci√≥n principal
‚îÇ   ‚îú‚îÄ‚îÄ API_DOCUMENTATION.md
‚îÇ   ‚îú‚îÄ‚îÄ DEPLOYMENT_GUIDE.md
‚îÇ   ‚îî‚îÄ‚îÄ test_api.py
‚îú‚îÄ‚îÄ models/             # Modelos entrenados
‚îÇ   ‚îú‚îÄ‚îÄ actionAbecedario.h5
‚îÇ   ‚îî‚îÄ‚îÄ actionPalabrasV2.h5
‚îú‚îÄ‚îÄ test/              # Archivos de prueba
‚îÇ   ‚îú‚îÄ‚îÄ secuencia_r.json
‚îÇ   ‚îî‚îÄ‚îÄ secuencia_adios.json
‚îî‚îÄ‚îÄ datasets/          # Datasets de entrenamiento
```

## Modelos de Machine Learning

### Especificaciones T√©cnicas

- **Framework**: TensorFlow 2.17.0 / Keras 3.5.0
- **Arquitectura**: LSTM/CNN (dependiendo del modelo)
- **Entrada**: Secuencias de keypoints (30 frames √ó 126/258 caracter√≠sticas)
- **Salida**: Clasificaci√≥n multiclase

### Alfabeto LSC (27 clases)
```
A, B, C, D, E, F, G, H, I, J, K, L, M, N, √ë, O, P, Q, R, S, T, U, V, W, X, Y, Z
```

### Palabras LSC V2 (28 clases)
```
sordo, hola, bien, mal, adios, bienvenido, gracias, perdon, permiso,
yo, tu, el, ella, nosotros, usted, ustedes, que, cuando, donde,
como, quien, cuanto, cual, buenos dias, buenas tardes, buenas noches, 
como estas, por favor
```

## Procesamiento de Video

### Pipeline de Procesamiento

1. **Captura de Video**: OpenCV lee frames del video
2. **Detecci√≥n MediaPipe**: Extracci√≥n de keypoints de pose y manos
3. **Normalizaci√≥n**: Conversi√≥n a formato est√°ndar
4. **Muestreo**: Adaptaci√≥n a longitud de secuencia requerida
5. **Predicci√≥n**: Inferencia del modelo
6. **Post-procesamiento**: Mapeo a etiquetas legibles

### Tipos de Extracci√≥n

#### Modo `hands` (126 caracter√≠sticas)
- 21 puntos por mano √ó 3 coordenadas (x, y, z) √ó 2 manos
- Ideal para se√±as que involucran principalmente las manos

#### Modo `pose_hands` (258 caracter√≠sticas)
- 33 puntos de pose √ó 4 coordenadas (x, y, z, visibility)
- 21 puntos por mano √ó 3 coordenadas √ó 2 manos
- Incluye contexto del cuerpo completo

## Monitoreo y Logs

### Logs de Aplicaci√≥n

La aplicaci√≥n registra:
- Carga de modelos
- Errores de predicci√≥n
- Informaci√≥n de procesamiento de video

### M√©tricas Recomendadas

- **Latencia de respuesta**: < 5 segundos para keypoints, < 30 segundos para video
- **Throughput**: Requests por segundo
- **Tasa de error**: Porcentaje de predicciones fallidas
- **Uso de recursos**: CPU, memoria, GPU

## Seguridad

### Configuraciones de Seguridad

- **CORS**: Configurado para dominios espec√≠ficos
- **Validaci√≥n de entrada**: Verificaci√≥n de formato de datos
- **Manejo de errores**: Respuestas de error estructuradas
- **Autenticaci√≥n**: Configurable seg√∫n necesidades

### Recomendaciones

1. **HTTPS**: Usar siempre en producci√≥n
2. **Rate Limiting**: Implementar l√≠mites de requests
3. **Validaci√≥n**: Verificar URLs de video y formatos de datos
4. **Logs**: Monitorear acceso y errores

## Mantenimiento

### Actualizaci√≥n de Modelos

1. **Entrenar nuevo modelo**
2. **Reemplazar archivo .h5 en models/**
3. **Actualizar constants.py si cambian las clases**
4. **Redesplegar aplicaci√≥n**

### Backup y Recuperaci√≥n

- **Modelos**: Backup de archivos .h5
- **Configuraci√≥n**: Versionado en Git
- **Datos**: Backup de datasets de entrenamiento

## Troubleshooting

### Problemas Comunes

1. **Error de carga de modelo**:
   - Verificar que los archivos .h5 est√©n en models/
   - Verificar permisos de archivo

2. **Error de MediaPipe**:
   - Verificar instalaci√≥n de dependencias
   - Verificar versi√≥n de OpenCV

3. **Error de memoria en Cloud Run**:
   - Aumentar memoria asignada
   - Optimizar carga de modelos

4. **Timeout en procesamiento de video**:
   - Aumentar timeout de Cloud Run
   - Optimizar algoritmo de procesamiento

### Logs de Debug

```python
# Habilitar logs detallados
import logging
logging.basicConfig(level=logging.DEBUG)
```

## Contribuci√≥n

### Gu√≠as de Desarrollo

1. **C√≥digo**: Seguir PEP 8
2. **Documentaci√≥n**: Actualizar README.md
3. **Testing**: Probar endpoints antes de commit
4. **Versionado**: Usar versionado sem√°ntico

### Proceso de Contribuci√≥n

1. Fork del repositorio
2. Crear rama feature
3. Implementar cambios
4. Probar localmente
5. Crear Pull Request

## Licencia

[Especificar licencia del proyecto]

## Contacto

[Informaci√≥n de contacto del equipo de desarrollo]

---

**Nota**: Esta documentaci√≥n est√° dise√±ada para desarrolladores y DevOps que necesiten desplegar y mantener la API de reconocimiento de LSC en entornos de producci√≥n.
